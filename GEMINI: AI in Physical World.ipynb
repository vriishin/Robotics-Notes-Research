{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60187087",
   "metadata": {},
   "source": [
    "# Gemini Robotics: Bringing AI into the Physical World\n",
    "### Authors: Gemini Robotics team, Year: 25 Mar [2025], Institution: Google DeepMind\n",
    "### Link:(https://arxiv.org/html/2503.20020v1)\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Problem Context & Motivation\n",
    "- There is difficulty translating the capabilities of large multimodal models from digital tasks to the physical world via robots. E.g. there are models that are able to identify objects, but getting a robot to move a soup can over a pan right next to it might be difficult.\n",
    "- Particularly relevant now because physical agents (robots) are desirable for generalist tasks, which requires to them needing to have a data-heavy backbone (e.g gemini 2 VLM)\n",
    "- Previous work in VLM's (Vision language models) were able to accurately interpret images but can't generate robot actions or properly work in a 3d space. \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Prior Work and State-of-the-Art\n",
    "- Key work and SoTA is the pi0 generalist policy\n",
    "- π₀ combines a pre-trained vision-language model (the backbone that gives reasoning) + flow‑matching for continuous control (i.e. making robot actions smooth) + training from different robot types + a two-stage training recipe (pretraining on general work -> fine tuning on task). \n",
    "- Brought zero-shot generalization (can handle new tasks without retraining), high-frequency smooth dexterity (robot moves fluidly/naturally with instructions at 50 Hz), and cross‑robot adaptability (form of robot doesnt matter.)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Summary of the Paper’s Contributions\n",
    "\n",
    "- Gemini Robotics is merging the power of large multimodal models (text + vision + action) with real-world robot control.\n",
    "- paper introduces reasoning benchmark Embodied Reasoning Question Answering (ERQA) and 2 models both with Gemini 2.0 as VLM backbone. \n",
    "    - Gemini 2.0 model  excels at tasks like detecting objects and points in 2D, leveraging 2D pointing for grasping and trajectories, and corresponding points and detecting objects in 3D. This is a large step towards bringing the reasoning capabilities of consumer tools, like ChatGPT, to robotics.\n",
    "    1. Gemini Robotics-ER: Focuses on understanding the physical world — it reasons about objects, space, and actions using just images and text.\n",
    "\n",
    "    2. Gemini Robotics: Builds on ER but adds direct robot control. It can execute tasks like folding clothes, packing lunch boxes, and even playing cards using real robots.\n",
    "\n",
    "    Gemini Robotics can turn instructions like \"zip the lunch bag\" into precise motor actions, in real-time, 50Hz robot motion. Furthermore, is exceptionally generalized - it can handle new environments, instructions (including typos in language), and robot types. Can perform new tasks without training (zero-shot) and improves when given new data (few shot). Also, with further tuning, it can complete complicated multi-step tasks like doing origami.\n",
    "---\n",
    "\n",
    "### 4. Technical Methods (with Plain Language Explanation)\n",
    "- Pretrained model (Gemini 2) with onboard encoder to deliver actions at 50Hz and ~250ms from input to action\n",
    "- Gemini Robotics is a very large model that was trained on multimodal data + robot demonstrations + robot state data (poses in variety of environments)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Experimental Results and Performance\n",
    "- Summary of the main results and where they were tested\n",
    "- Key benchmarks and evaluation metrics\n",
    "- Performance relative to previous methods\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Comparison to Prior Work\n",
    "- Summary of how this method improves over earlier work\n",
    "- The previous SoTA model, PI0 was outperfomed by Gemini robotics.\n",
    "- Gemini was able to accomplish this by improving on a variety of aspects:\n",
    "1. Gemini 2.0 is a much larger model than the 3B token model PI0 used as its backbone\n",
    "2. Gemini was trained on a more diverse data set (see 4)\n",
    "3. Gemini includes an embodied reasoning (gemini ER) layer that allows it to reason through 3D envs, predict actions, and infer\n",
    "4. Gemini and PI0 were both fine tuned on tasks, however Gemini had extensive training on multi step tasks \n",
    "\n",
    "---\n",
    "\n",
    "### 7. Broader Implications and Applications\n",
    "- Gemini has established itself as the new SoTA for general task 3D space interaction\n",
    "- Because of Zero shot and few shot capabilities, this model can be deployed faster than previous related tools like RT and PI0\n",
    "- Reestablishes/improves feasibility of generalist robot\n",
    "\n",
    "\n",
    "### 8. Related Papers and Integration Points\n",
    "- Mention other directly related papers\n",
    "- Explain how this work builds on, improves, or contrasts with them\n",
    "- Include internal links to other notebook summaries if applicable\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 10. Executive Summary\n",
    "- One-paragraph summary focused on business relevance\n",
    "- What problem it solves\n",
    "- How it improves upon earlier approaches\n",
    "- What it enables in real-world robotics or automation contexts\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
