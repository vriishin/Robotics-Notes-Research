{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc03508f",
   "metadata": {},
   "source": [
    "# BEAST: B-Spline Encoded Action Sequence Tokenizer\n",
    "\n",
    "**Reference:** Zhou et al., 2506.06072v2, Jun 10 2025\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0a77c",
   "metadata": {},
   "source": [
    "BEAST is a new way to compress a series of actions into a smaller number of tokens for a robot. The tokenization based approach has seen positive feedback based on its efficacy in NLP, however applying it to robotics has not been straightforward. \n",
    "\n",
    "> Different from tokenizers based on the vector quantization [13 – 15], it does not require additional tokenizer training.\n",
    "BEAST compresses action trajectories into fixed-length token sequences enabling efficient parallel\n",
    "decoding for faster token generation, requiring 4 − 8× fewer tokens than binning-based tokenization\n",
    "\n",
    "Downsides from previous methods for encoding (like vector quantization or binning):  \n",
    "1. Need to train separate encoder-decoder networks (adds complexity).\n",
    "2. Different length token sequences, even for actions of the same length - causes issues in decoding quickly.\n",
    "3. Gaps between chunks - not smooth, flowing actions.\n",
    "        \n",
    "A previous method, FAST, encoded actions using DCT and byte pair encoding (can treat this as a black box). Importantly, this method produced varied length sequences. This was seen as an issue because this makes parallel decoding more difficult. \n",
    "\n",
    "BEAST has shown itself to be more computationally efficient as well as requiring less training than previous models. \n",
    "Late in the paper BEAST used with Florence 2 (a VLA) is compared against pi0 and pi0+FAST in LIBERO (a benchmarking set of tasks). Ended up performing marginally worse than pi0 (beat pi0+fast), and is a much smaller model with no pretraining. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb83511",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "BEAST is built on B-Splines which, generally, are a way of creating curves on a graph using a few key points.\n",
    "Comparison using clamped B-splines vs \n",
    "\n",
    "B-Splines are inherently related to action chunking because it is a piecewise function,  action chuncking is a 0th degree bspline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a92a6e",
   "metadata": {},
   "source": [
    "## Experiments:\n",
    "\n",
    "1. What advantages does BEAST offer over commonly used binning-based tokenizers?\n",
    "\n",
    "BEAST is significantly more compact and smooth.\n",
    "- It uses 4–8× fewer tokens than binning methods.\n",
    "- Instead of encoding every individual action step, BEAST encodes entire chunks of actions using B-spline control points\n",
    "- This results in smoother motion and more natural transitions between chunks, unlike binning, which can produce jerky or abrupt movements.\n",
    "\n",
    "Summary: BEAST summarizes motion efficiently and gracefully, whereas binning treats every tiny detail separately.\n",
    "\n",
    "2. How does BEAST contribute to the performance on imitation learning benchmarks?\n",
    "\n",
    "BEAST improves imitation learning performance.\n",
    "- It matches or outperforms existing tokenizers on both simulated and real-world robot benchmarks.\n",
    "- Its ability to encode longer and more coherent action sequences leads to better task success rates and model stability.\n",
    "- Replacing other tokenizers with BEAST in existing models often leads to measurable improvements.\n",
    "\n",
    "Summary: BEAST helps models learn how motion flows, not just what happens step by step.\n",
    "\n",
    "3. How does BEAST affect the training and inference efficiency?\n",
    "\n",
    "BEAST is faster and simpler to use.\n",
    "- It requires no additional training (unlike methods based on vector quantization).\n",
    "- BEAST directly uses mathematical B-spline fitting, avoiding the need for encoder-decoder tokenizers.\n",
    "- It enables parallel decoding, which speeds up inference and makes the system more efficient.\n",
    "\n",
    "Summary: BEAST reduces system complexity and speeds up inference without sacrificing performance.\n",
    "\n",
    "4. Does BEAST generalize to real-world scenarios?\n",
    "\n",
    "Yes — BEAST generalizes well to real robots.\n",
    "- It has been successfully tested on physical robots in tasks involving manipulation and object interaction.\n",
    "- The motions it generates are smooth and continuous, making it suitable for real environments.\n",
    "- BEAST performs well even in previously unseen settings and action types.\n",
    "\n",
    "\n",
    "\n",
    "5. How do the design choices affect the performance of BEAST?\n",
    "\n",
    "BEAST’s performance depends on spline configuration.\n",
    "- Ablation studies show that the number of control points, the spline degree, and whether the spline is clamped all affect performance.\n",
    "- Using too few control points can result in underfitting; too many can reduce efficiency.\n",
    "- Spline degree controls how smooth the generated motion is and how well it generalizes.\n",
    "\n",
    "Summary: BEAST is robust, but thoughtful tuning of its spline parameters yields the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644113f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff93a604",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b22a8553",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
