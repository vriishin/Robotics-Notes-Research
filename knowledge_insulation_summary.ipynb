{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af5e582",
   "metadata": {},
   "source": [
    "# Knowledge Insulating Vision-Language-Action Models\n",
    "\n",
    "**Reference:** Driess et al., pi05_KI.pdf\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc02a06",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Analyzes the degradation of semantic knowledge when training VLAs with continuous action adapters. Proposes **knowledge insulation**, separating gradient flows: discrete tokens train the VLM backbone, while a continuous action expert learns flow/diffusion outputs without affecting the backbone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3345f0c0",
   "metadata": {},
   "source": [
    "## Key Contributions\n",
    "\n",
    "- Identified harmful gradient interference from untrained continuous adapters.\n",
    "- Introduced gradient-blocking between action expert and VLM backbone.\n",
    "- Achieved faster, more stable training with preserved language and vision capabilities.\n",
    "\n",
    "![Knowledge Insulation](https://pi.website/research/knowledge_insulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0623c5",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "1. **Discrete Backbone Training:** Use next-token prediction on discretized actions and general VLM data.\n",
    "2. **Continuous Action Expert:** Train diffusion/flow-matching head on continuous actions.\n",
    "3. **Stop Gradients:** Block expert gradients to preserve pre-trained VLM representations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959bd56a",
   "metadata": {},
   "source": [
    "## Experiments & Results\n",
    "\n",
    "- Ablation studies showing backbone degradation without insulation.\n",
    "- Faster convergence and improved zero-shot language following.\n",
    "- Maintained continuous inference speed and precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce53f9",
   "metadata": {},
   "source": [
    "## Connections to Other Papers\n",
    "\n",
    "- Builds on FAST tokenization to train discrete backbone.  \n",
    "- Provides the training recipe used in π0.5’s two-stage pipeline.  \n",
    "- Supports real-time chunking by ensuring reliable VLM features.\n",
    "\n",
    "**Key Related Works:**\n",
    "- π0 flow-matching VLA [7]\n",
    "- FAST tokenization [37]\n",
    "- Diffusion VLA methods [20]"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
